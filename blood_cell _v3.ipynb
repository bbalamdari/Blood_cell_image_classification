{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4w_1zf4RKsC"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZUu_KS6hja7",
        "outputId": "d761232c-7f89-4b9d-e927-dcaba1b097b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/grive; to attempt to forcibly remount, call drive.mount(\"/content/grive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount into drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/grive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX9fJ3BbhjXy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiGiHRFox1tw"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Set deterministic convolution algorithm\n",
        "os.environ['CUDNN_DETERMINISTIC'] = 'true'\n",
        "\n",
        "# Set deterministic cuDNN benchmark\n",
        "os.environ['CUDNN_BENCHMARK'] = 'false'\n",
        "\n",
        "# Set a fixed random seed\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQJa05UuNnYe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oV5K3DUhjdr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vcdXHzdhjg_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Set fixed random seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class SpatialPyramidPooling(nn.Module):\n",
        "    def __init__(self, output_sizes):\n",
        "        super(SpatialPyramidPooling, self).__init__()\n",
        "        self.output_sizes = output_sizes\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, height, width = x.size()\n",
        "        pooled_features = []\n",
        "\n",
        "        for output_size in self.output_sizes:\n",
        "            kh, kw = height // output_size, width // output_size\n",
        "            ph, pw = height % output_size, width % output_size\n",
        "\n",
        "            if ph == 0 and pw == 0:\n",
        "                pooled_features.append(F.max_pool2d(x, kernel_size=(kh, kw), stride=(kh, kw)))\n",
        "            else:\n",
        "                x_padded = F.pad(x, (0, pw, 0, ph))\n",
        "                pooled_features.append(F.max_pool2d(x_padded, kernel_size=(kh, kw), stride=(kh, kw)))\n",
        "\n",
        "        x = torch.cat(pooled_features, dim=1)\n",
        "        x = x.view(batch_size, -1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, dilation=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            Swish(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, dilation=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            Swish(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, dilation=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            Swish(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, dilation=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            Swish(),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, dilation=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            Swish(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            SpatialPyramidPooling(output_sizes=[4, 4, 4])\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 48, 512),\n",
        "            Swish(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(512, 512),\n",
        "            Swish(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            Swish(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(256, 4)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjW4w_v8gTYW"
      },
      "outputs": [],
      "source": [
        "# Set a fixed random seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define weight initialization\n",
        "def weight_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_uniform_(m.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j4OrYqvw8YA",
        "outputId": "c5753fbe-1c35-4d78-9b22-9670e0f204be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): Swish()\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): Swish()\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): Swish()\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): Swish()\n",
              "    (13): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (15): Swish()\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): SpatialPyramidPooling()\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=24576, out_features=512, bias=True)\n",
              "    (1): Swish()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (4): Swish()\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (7): Swish()\n",
              "    (8): Dropout(p=0.5, inplace=False)\n",
              "    (9): Linear(in_features=256, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Define your model\n",
        "num_classes = 4\n",
        "model = MyModel().to(device)\n",
        "# Initialize the model\n",
        "model.apply(weight_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAtPYuViG7B2",
        "outputId": "c5365c3c-ff81-41e8-bd9d-5b58b0d5718f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input size before the first linear layer: 24576\n"
          ]
        }
      ],
      "source": [
        "# Calculate the output size of feature extraction --this is just for check\n",
        "model = MyModel()\n",
        "dummy_input = torch.randn(1, 3, 224, 224)  # Batch size 1, 3 channels, 224x224 image\n",
        "features_output = model.features(dummy_input)\n",
        "num_features = features_output.size(1)\n",
        "print(\"Input size before the first linear layer:\", num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD7d0dfEHBU_"
      },
      "outputs": [],
      "source": [
        "base = '/content/grive/MyDrive/archive (1)/dataset2-master/dataset2-master/images/TRAIN'\n",
        "training_set = '/content/grive/MyDrive/images/filtered/mix_images'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osvIOkSwz1Kw"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set a fixed random seed for data loader\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define the directory path and image transformations\n",
        "train_directory = training_set\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Create the ImageFolder dataset\n",
        "train_dataset = ImageFolder(train_directory, transform=image_transforms)\n",
        "\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# Define the number of images to sample\n",
        "n = 4 * 250\n",
        "\n",
        "# Get the total number of images in the dataset\n",
        "total_images = len(train_dataset)\n",
        "\n",
        "# Generate random indices to sample from the dataset\n",
        "#random_indices = random.sample(range(total_images), n)\n",
        "\n",
        "# Create a Subset of the dataset with the randomly sampled indices\n",
        "#sampled_dataset = Subset(train_dataset, random_indices)\n",
        "\n",
        "# Create the DataLoader\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for the sampled dataset\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ65hoWzqUrH",
        "outputId": "7eb26ef6-242d-4c5a-aeb9-8d0d7bc7a1cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Label: EOSINOPHIL, Class Index: 0\n",
            "Class Label: LYMPHOCYTE, Class Index: 1\n",
            "Class Label: MONOCYTE, Class Index: 2\n",
            "Class Label: NEUTROPHIL, Class Index: 3\n"
          ]
        }
      ],
      "source": [
        "# Get the class labels and their corresponding indixes\n",
        "class_labels = train_dataset.classes\n",
        "class_indices = train_dataset.class_to_idx\n",
        "\n",
        "# Mapping between class labels and indixes\n",
        "for label, index in class_indices.items():\n",
        "    print(f\"Class Label: {label}, Class Index: {index}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3Yi1DIiX9mT",
        "outputId": "3a6a1c29-1681-4576-de3d-066e1ac9136f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 2.721810591347674 Training accuracy: 24.83%\n",
            "Epoch 2: Loss: 1.494148740108977 Training accuracy: 25.90%\n",
            "Epoch 3: Loss: 1.4457717550561784 Training accuracy: 23.60%\n",
            "Epoch 4: Loss: 1.4273419082164764 Training accuracy: 26.10%\n",
            "Epoch 5: Loss: 1.4116973433088749 Training accuracy: 25.17%\n",
            "Epoch 6: Loss: 1.4057255666306678 Training accuracy: 24.73%\n",
            "Epoch 7: Loss: 1.3954755720940042 Training accuracy: 26.43%\n",
            "Epoch 8: Loss: 1.3959183344181547 Training accuracy: 25.23%\n",
            "Epoch 9: Loss: 1.3849595709049956 Training accuracy: 25.87%\n",
            "Epoch 10: Loss: 1.393145741934472 Training accuracy: 23.57%\n",
            "Epoch 11: Loss: 1.388344315772361 Training accuracy: 23.83%\n",
            "Epoch 12: Loss: 1.3894355442929776 Training accuracy: 24.27%\n",
            "Epoch 13: Loss: 1.386211487841099 Training accuracy: 26.13%\n",
            "Epoch 14: Loss: 1.3857553322264489 Training accuracy: 26.20%\n",
            "Epoch 15: Loss: 1.3867575253577942 Training accuracy: 25.03%\n",
            "Training time: 3572.465615272522\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import time\n",
        "\n",
        "# Set a fixed random seed for data loader\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Move the criterion to the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "model = model.to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 15\n",
        "best_loss = float('inf')\n",
        "patience = 10\n",
        "counter = 0\n",
        "\n",
        "# Create the learning rate scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "start = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    # Accumulate gradients over multiple batches\n",
        "    total_loss = 0.0\n",
        "    accumulation_steps = 4\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
        "        batch_images = batch_images.to(device)  # Send the input tensor to the appropriate device\n",
        "        batch_labels = batch_labels.to(device)  # Send the input tensor to the appropriate device\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Perform forward pass\n",
        "        outputs = model(batch_images)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform gradient accumulation\n",
        "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Calculate the accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct_predictions += (predicted == batch_labels).sum().item()\n",
        "\n",
        "    total_loss /= len(train_loader)\n",
        "\n",
        "\n",
        "    # Update the learning rate scheduler\n",
        "    scheduler.step(total_loss)\n",
        "\n",
        "    # Epoch information and Calculate the accuracy\n",
        "    accuracy = correct_predictions / len(train_loader.dataset) * 100\n",
        "    print(f\"Epoch {epoch + 1}: Loss: {total_loss}\", f\"Training accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    # Check for early stopping\n",
        "    if total_loss < best_loss:\n",
        "        best_loss = total_loss\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(f\"Training time: {end - start}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ybo__ZgubZeB"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "torch.save(model.state_dict(), '/content/grive/MyDrive/model_objects/filtered/mix_images_july23_dialted3.pht')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_WUxwzk4Wep"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model_upload = torch.load('/content/grive/MyDrive/model_objects/filtered/mix_images_6th_0_swish.pht', map_location=device)\n",
        "\n",
        "# Create an instance of MyModel\n",
        "model = MyModel()\n",
        "\n",
        "# Copy the loaded weights and biases to the model\n",
        "model.load_state_dict(model_upload)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "qvYMiy-Em8Gb",
        "outputId": "e79a459d-4a9e-4a35-ae0e-29dea77da3c2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-8aa9a89831e4>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Predict on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mbatch_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[1;32m    228\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2982\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2984\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2986\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train set prediction\n",
        "from tensorflow.python.ops.math_ops import truncate_div\n",
        "appended_preds = torch.tensor([]).to(device)\n",
        "appended_true = torch.tensor([]).to(device)\n",
        "\n",
        "# Predict on the test set\n",
        "with torch.no_grad():\n",
        "    for batch_images, batch_labels in train_loader:\n",
        "        batch_images = batch_images.to(device)\n",
        "        outputs = model(batch_images)\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        probabilities = softmax(outputs)\n",
        "        _, predicted_indices = torch.max(probabilities, dim=1)\n",
        "        appended_preds = torch.cat((appended_preds, predicted_indices), dim=0)\n",
        "        appended_true = torch.cat((appended_true, batch_labels.to(device)), dim=0)\n",
        "\n",
        "\n",
        "# Train set accuracy\n",
        "total = len(appended_true)\n",
        "correct = (appended_preds == appended_true).sum().item()\n",
        "accuracy = correct / total * 100\n",
        "\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al-qAwt9AcKe"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMkw2kU76NZx"
      },
      "outputs": [],
      "source": [
        "test_set = '/content/grive/MyDrive/images/test_set'\n",
        "\n",
        "# Test set accuracy\n",
        "test_directory = test_set\n",
        "test_image_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Create the ImageFolder dataset\n",
        "test_dataset = ImageFolder(test_directory, transform=test_image_transforms)\n",
        "\n",
        "import random\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# Define the number of images to sample\n",
        "n = 4 * 250\n",
        "\n",
        "# Get the total number of images in the dataset\n",
        "test_total_images = len(test_dataset)\n",
        "\n",
        "\n",
        "# Generate random indices to sample from the dataset\n",
        "random_indices = random.sample(range(test_total_images), n)\n",
        "\n",
        "# Create a Subset of the dataset with the randomly sampled indices\n",
        "#test_sampled_dataset = Subset(test_dataset, random_indices)\n",
        "\n",
        "# Create the DataLoader\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for the sampled dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Eo3Ihc29aD8",
        "outputId": "028f0352-9063-4f64-fafa-27726d06945f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Label: EOSINOPHIL, Class Index: 0\n",
            "Class Label: LYMPHOCYTE, Class Index: 1\n",
            "Class Label: MONOCYTE, Class Index: 2\n",
            "Class Label: NEUTROPHIL, Class Index: 3\n"
          ]
        }
      ],
      "source": [
        "# Get the class labels and their corresponding indixes\n",
        "class_labels = test_dataset.classes\n",
        "class_indices = test_dataset.class_to_idx\n",
        "\n",
        "for label, index in class_indices.items():\n",
        "    print(f\"Class Label: {label}, Class Index: {index}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MQ4xcdR7W8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a252f8-b402-413f-fd47-393aaac99595"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25.1"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Test set prediction\n",
        "from tensorflow.python.ops.math_ops import truncate_div\n",
        "test_appended_preds = torch.tensor([]).to(device)\n",
        "test_appended_true = torch.tensor([]).to(device)\n",
        "\n",
        "# Predict on the test set\n",
        "with torch.no_grad():\n",
        "    for batch_images, batch_labels in test_loader:\n",
        "        batch_images = batch_images.to(device)\n",
        "        outputs = model(batch_images)\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        probabilities = softmax(outputs)\n",
        "        _, predicted_indices = torch.max(probabilities, dim=1)\n",
        "        test_appended_preds = torch.cat((test_appended_preds, predicted_indices), dim=0)\n",
        "        test_appended_true = torch.cat((test_appended_true, batch_labels.to(device)), dim=0)\n",
        "\n",
        "\n",
        "# Test set accuracy\n",
        "test_total = len(test_appended_true)\n",
        "test_correct = (test_appended_preds == test_appended_true).sum().item()\n",
        "test_accuracy = test_correct / test_total * 100\n",
        "\n",
        "test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "2aV77fwDnp2w",
        "outputId": "1b02c769-f956-4432-a076-7e34c82f3356"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "# Define the class labels\n",
        "class_labels = ['0', '1', '2', '3']\n",
        "\n",
        "# Convert to numpy\n",
        "predicted = test_appended_preds.cpu().numpy()\n",
        "true = test_appended_true.cpu().numpy()\n",
        "\n",
        "# Confusion matrix with normalization\n",
        "cm = confusion_matrix(true, predicted, normalize='true')\n",
        "\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "\n",
        "cm_display.plot(include_values=True, values_format='.2f')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uEFbpR0zrmy"
      },
      "source": [
        "# extract images after layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvjeTetM7aUl"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "\n",
        "device = torch.device('cpu')  # Specify the device as CPU\n",
        "\n",
        "# Move the model to the specified device\n",
        "model.to(device)\n",
        "\n",
        "# Define the target layers whose intermediate images you want to visualize\n",
        "target_layers = [model.features[0], model.features[13]]\n",
        "\n",
        "# Define a dictionary to store the intermediate images\n",
        "intermediate_images = {}\n",
        "\n",
        "# Define a hook function to capture the intermediate images\n",
        "def hook_fn(module, input, output):\n",
        "    intermediate_images[str(module)] = output.detach()\n",
        "\n",
        "# Register the hook for each target layer\n",
        "for layer in target_layers:\n",
        "    layer.register_forward_hook(hook_fn)\n",
        "\n",
        "# Load and preprocess the image\n",
        "image_path = '/content/grive/MyDrive/images/filtered/BASE/EOSINOPHIL/_0_5579.jpeg'\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Preprocess the image\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), I am still not sure if we need this normalization or not.\n",
        "])\n",
        "\n",
        "# Move the input image tensor to the specified device\n",
        "image = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "# Pass the image through the model to get the output\n",
        "output = model(image)\n",
        "\n",
        "# Access the intermediate images from the dictionary\n",
        "for layer_name, image in intermediate_images.items():\n",
        "    # Split the tensor into separate channels\n",
        "    image_channels = torch.split(image, 1, dim=1)\n",
        "\n",
        "    # Specify the output directory and filename\n",
        "    output_directory = \"/content/grive/MyDrive/images/intermediate_images_initial_model\"\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "    output_filename = f\"{layer_name}_result_image.jpg\"\n",
        "    output_path = os.path.join(output_directory, output_filename)\n",
        "\n",
        "    # Convert each channel to a PIL image and save it\n",
        "    for i, channel in enumerate(image_channels):\n",
        "        channel_pil = transforms.ToPILImage()(channel.squeeze().cpu())\n",
        "        channel_pil.save(output_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}